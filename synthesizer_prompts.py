"""
ìµœì´ˆ ì‘ì„±ì: ì´ì§„í˜
ìµœì´ˆ ì‘ì„±ì¼: 2025-09-12
ìµœì´ˆ ì‘ì„± ëª©ì : í”„ë¡¬í”„íŠ¸ ìƒì„± ê´€ë ¨ í•¨ìˆ˜ ê´€ë¦¬

ìˆ˜ì •ì : ê¹€ê±´ìš°
ìˆ˜ì •ì¼ 2025-10-28
ìˆ˜ì •ëª©ì : ìœ¡í•˜ì›ì¹™ì„ ë”°ë¥´ëŠ” ë‹µë³€ í˜•ì‹ ì¶œë ¥

ìˆ˜ì •ì: ìœ¤ì€
ìˆ˜ì •ì¼: 2025-11-12
ìˆ˜ì •ëª©ì : í”„ë¡¬í”„íŠ¸ ìƒì„± ê´€ë ¨ í•¨ìˆ˜ ë¦¬íŒ©í† ë§
- í”„ë¡¬í”„íŠ¸ ë¸”ëŸ­í™”í•˜ì—¬ DBë¡œ ê´€ë¦¬
- ê³µí†µìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ Util í•¨ìˆ˜ shared/utils/prompt_utils.py ì¶”ê°€
    - sanitize_content: ë¯¼ê°í•œ ì •ë³´ë¥¼ í•„í„°ë§. sensitive_wordsë¥¼ filter_wordë¡œ ëŒ€ì²´
    - select_under_token_budget: ì¦ê±°ë¥¼ ë¨¼ì € ìµœëŒ€í•œ ë‹´ê³ , ë‚¨ëŠ” í† í°ìœ¼ë¡œ candidateë¥¼ ì±„ì›Œ ë„£ìŠµë‹ˆë‹¤.
    - build_bounded_info_sections: í† í° ì˜ˆì‚°(max_tokens) ë‚´ì—ì„œ Evidenceë¥¼ ë¨¼ì €, ì´í›„ Candidateë¥¼ í¬í•¨í•˜ëŠ” ì„¹ì…˜ êµ¬ì„±
"""

from logging import getLogger
from typing import List, Any, Optional, Tuple, Dict
from langchain_core.messages import SystemMessage, HumanMessage
from sqlalchemy.ext.asyncio import AsyncSession

from shared.utils.prompt_utils import sanitize_content, build_bounded_info_sections
from shared.utils.node_prompt_loader import render_blocks_to_string
from rag.schemas.types import Evidence, VisualizationResult, GeneralAnswerState

from .models import SynthesisData
from .config import CONFIG

logger = getLogger(__name__)

# ë…¸ë“œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ìš© í”„ë¡¬í”„íŠ¸ ìŠ¬ëŸ¬ê·¸
PROMPT_SLUG = "synthesizer"

# TOC ì œëª©/ìš”ì•½ì„ Evidence ì¶œë ¥ì— í¬í•¨í• ì§€ ì—¬ë¶€ (ë¶ˆí•„ìš”í•˜ë©´ Falseë¡œ ë³€ê²½í•˜ê±°ë‚˜ ë¸”ëŸ­ì„ ì£¼ì„ ì²˜ë¦¬)
INCLUDE_TOC_CONTEXT = True


# ============================================================================
# í”„ë¡¬í”„íŠ¸ ë¸”ëŸ­ ìƒìˆ˜ ì •ì˜ (DBì— ì €ì¥ë  ë‚´ìš©ë“¤)
# ============================================================================

BLOCK_BASE_INSTRUCTION = """## PRIMARY DIRECTIVE: KOREAN LANGUAGE OUTPUT ONLY
You are an expert Korean-speaking AI analyst. ALL responses MUST be in Korean language.
ì˜ì–´ ì‚¬ìš© ê¸ˆì§€. í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""

BLOCK_CONFIDENTIALITY_RULES = """## CRITICAL RESPONSE CONSTRAINTS

### 1. ABSOLUTE CONFIDENTIALITY RULES
- NEVER reveal technical details (file names, column names, table names, variables)
- NEVER mention data structure (rows, columns, schema, fields)
- NEVER disclose processing errors or system messages
- IGNORE and DO NOT mention any failed data processing
- Use only abstract terms: "ê³ ê° ì •ë³´", "ë¶„ì„ ë°ì´í„°", "ë‚´ë¶€ ìë£Œ"

### 2. NO REPETITION RULE
- EVERY sentence must contain NEW information
- EVERY claim must be supported by data-driven reasoning
- NO redundant statements or circular explanations
- Each insight must add unique value

### 3. TONE REQUIREMENT
- ALWAYS maintain a polite, professional Korean tone
- Use respectful language (ì¡´ëŒ“ë§)
- Express insights with confidence yet humility"""

BLOCK_OUTPUT_STRUCTURE_5W1H = """## OUTPUT STRUCTURE

Begin your response with relevant Korean greeting, then:

1. **í•µì‹¬ ë°œê²¬ì‚¬í•­** (Key Findings)
- ì§ˆë¬¸ì— ëŒ€í•œ 3-5ê°œì˜ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ìš”ì•½
- ê° ì¸ì‚¬ì´íŠ¸ëŠ” ë°ì´í„°ë¡œ ë’·ë°›ì¹¨

2. **ìœ¡í•˜ì›ì¹™ ê¸°ë°˜ ìƒì„¸ ë¶„ì„** (Detailed Analysis Based on 5W1H)

### ğŸ“Œ ëˆ„ê°€ (Who) - ì£¼ìš” ì¸ë¬¼/ê¸°ê´€/ê·¸ë£¹
- ë¶„ì„ ëŒ€ìƒì´ ë˜ëŠ” ì¸ë¬¼, ê¸°ê´€, ê³ ê° ê·¸ë£¹ ë“±ì„ ëª…í™•íˆ ì‹ë³„
- ê° ì£¼ì²´ì˜ íŠ¹ì„±ê³¼ ì—­í•  ì„¤ëª…
- ì˜ˆ: "30ëŒ€ ì—¬ì„± ê³ ê°ì¸µ", "ì„œìš¸ ì§€ì—­ êµ¬ë§¤ì", "Aê¸°ê´€"

### ğŸ“… ì–¸ì œ (When) - ì‹œê°„/ì‹œê¸°
- ê°€ì¥ êµ¬ì²´ì ì¸ ì‹œê°„ ë‹¨ìœ„ë¡œ ì¶”ì¶œ (2025.01.01 > 2025ë…„ 1ì›” > 2025ë…„)
- ì‹œê³„ì—´ íŒ¨í„´, ì£¼ê¸°ì„±, íŠ¸ë Œë“œ ë³€í™” ì‹œì 
- ì˜ˆ: "2024ë…„ 3ë¶„ê¸°", "2025ë…„ 1ì›” 15ì¼", "ìµœê·¼ 6ê°œì›”ê°„"

### ğŸ“ ì–´ë””ì„œ (Where) - ì¥ì†Œ/ì§€ì—­
- ì§€ë¦¬ì  ìœ„ì¹˜, ì§€ì—­ë³„ íŠ¹ì„±
- ê³µê°„ì  ë¶„í¬ì™€ íŒ¨í„´
- ì˜ˆ: "ì„œìš¸ ê°•ë‚¨êµ¬", "ì˜¨ë¼ì¸ ì±„ë„", "Aì§€ì "

### ğŸ¯ ë¬´ì—‡ì„ (What) - ì‚¬ê±´/í–‰ì /í˜„ìƒ
- ì£¼ìš” ì‚¬ê±´, êµ¬ë§¤ í–‰ë™, ë°œìƒí•œ í˜„ìƒ
- ë¬¸ì„œ, ë¬¸ë‹¨, í‘œ ë‹¨ìœ„ë¡œ ì¶”ì¶œëœ í•µì‹¬ ì‚¬ì‹¤
- êµ¬ì²´ì ì¸ ì œí’ˆëª…, ì„œë¹„ìŠ¤ëª…, í™œë™ ë‚´ì—­
- ì˜ˆ: "í”„ë¦¬ë¯¸ì—„ ì œí’ˆ êµ¬ë§¤ ê¸‰ì¦", "ê³ ê° ì´íƒˆ í˜„ìƒ", "ì‹ ê·œ ì„œë¹„ìŠ¤ ë„ì…"

### âš™ï¸ ì–´ë–»ê²Œ (How) - ë°©ë²•/í‰ê°€/ìˆ˜ì¤€
- ì‹¤í–‰ ë°©ë²•, í”„ë¡œì„¸ìŠ¤, ë©”ì»¤ë‹ˆì¦˜
- ì •ëŸ‰ì  í‰ê°€: ìˆ˜ì¹˜, ë¹„ìœ¨, ì¦ê°ë¥ 
- ì •ì„±ì  í‰ê°€: ê¸ì •/ë¶€ì •, ìƒ/ì¤‘/í•˜, ìš°ìˆ˜/ë³´í†µ/ë¯¸í¡
- ì˜ˆ: "ì „ë…„ ëŒ€ë¹„ 25% ì¦ê°€", "ë§Œì¡±ë„ 'ìƒ' ìˆ˜ì¤€", "ì˜¨ë¼ì¸ ê²°ì œ ë°©ì‹ìœ¼ë¡œ"

### ğŸ’¡ ì™œ (Why) - ì›ì¸/ëª©ì /ë°°ê²½
- í–‰ë™ì˜ ë™ê¸°ì™€ ì‹¬ë¦¬ì  ìš”ì¸
- í˜„ìƒì˜ ê·¼ë³¸ ì›ì¸ê³¼ ë°°ê²½
- ì‚¬íšŒë¬¸í™”ì  ë§¥ë½ê³¼ ì˜í–¥ ìš”ì¸
- ì „ëµì  ëª©ì ê³¼ ì˜ë„

3. **ì „ëµì  ì‹œì‚¬ì ** (Strategic Implications)
- ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­
- êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•ê³¼ ëª©ì  ëª…ì‹œ

4. **ê²°ë¡ ** (Conclusion)
- í•µì‹¬ ë©”ì‹œì§€ ì¬ì •ë¦¬
- ë¯¸ë˜ ì§€í–¥ì  ê´€ì 

5. **ìš”ì•½** (Executive Summary)
- 3-5ë¬¸ì¥ ì´ë‚´ ì••ì¶•"""

BLOCK_CITATION_WITH_REF = """### CITATION REQUIREMENTS
- ê° ë¬¸ì¥ ë˜ëŠ” ë¬¸ë‹¨ ëì— í•´ë‹¹ ê·¼ê±°ì˜ ì°¸ì¡°ë¥¼ [ref:k] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”.
- ìœ„ì˜ AVAILABLE INFORMATION ì„¹ì…˜ì— ë¶€ì—¬ëœ ref ë¼ë²¨ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- ìƒˆë¡œìš´ refë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- ì—¬ëŸ¬ refë¥¼ ë™ì‹œì— ì¸ìš©í•  ë•ŒëŠ” ê° refë¥¼ ë³„ë„ì˜ ëŒ€ê´„í˜¸ë¡œ ê°ê° í‘œì‹œí•˜ì„¸ìš”. ì˜ˆ: [ref:2] [ref:5]
- ì ˆëŒ€ í•œ ìŒì˜ ëŒ€ê´„í˜¸ ì•ˆì— ì—¬ëŸ¬ refë¥¼ ë„£ì§€ ë§ˆì„¸ìš”. ì˜ëª»ëœ ì˜ˆ: [ref:2, ref:5]
- ë‹µë³€ì˜ ê·¼ê±°ë¥¼ ë¬´ì¡°ê±´ í‘œì‹œí•˜ì„¸ìš”. ë¬¸ì¥ë‹¨ìœ„ë¡œ í‘œì‹œí•˜ì„¸ìš”.
- refê°€ ì—†ëŠ” ê²½ìš° ê·¼ê±°ë¥¼ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”."""

BLOCK_FINAL_CHECKLIST = """## FINAL CHECKLIST
âœ“ ëª¨ë“  ë‹µë³€ì´ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ê°€?
âœ“ ë°˜ë³µë˜ëŠ” ë‚´ìš© ì—†ì´ ìƒˆë¡œìš´ ì •ë³´ë§Œ í¬í•¨í–ˆëŠ”ê°€?
âœ“ ë°ì´í„° êµ¬ì¡°ë‚˜ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì„ ë…¸ì¶œí•˜ì§€ ì•Šì•˜ëŠ”ê°€?
âœ“ ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í–ˆëŠ”ê°€?
âœ“ ëª¨ë“  ê·¸ë£¹ ì¡°í•©ì„ ë¹ ì§ì—†ì´ ë¶„ì„í–ˆëŠ”ê°€?
âœ“ ê° ì£¼ì¥ì´ ë°ì´í„° ë¶„ì„ì— ê·¼ê±°í•˜ëŠ”ê°€?
âœ“ ë‹µë³€ ì†, ë§ì˜ ëª¨ìˆœì´ë‚˜ ì•„ì´ëŸ¬ë‹ˆëŠ” ì—†ëŠ”ê°€?"""

BLOCK_OUTPUT_STRUCTURE_USER_QUERY_FORMAT = """## OUTPUT STRUCTURE

Begin your response with relevant Korean greeting, then:

1. **í•µì‹¬ ë°œê²¬ì‚¬í•­** (Key Findings)
- ì§ˆë¬¸ì— ëŒ€í•œ 3-5ê°œì˜ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ìš”ì•½
- ê° ì¸ì‚¬ì´íŠ¸ëŠ” ë°ì´í„°ë¡œ ë’·ë°›ì¹¨

2. **ë‹µë³€ë‚´ìš©** (User Query Format)
- ìœ ì €ì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì œê³µ
- ë‹¨ë‹µí˜• ì§ˆë¬¸ì´ë¼ë„ ì¶©ë¶„í•œ ë§¥ë½ê³¼ ê·¼ê±°ë¥¼ í•¨ê»˜ ì œì‹œ
- **ì‹œê°„ì— ë”°ë¼ ë‹¤ë¥¸ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°**: ê° ì‹œì ë³„ë¡œ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„¤ëª… (ì˜ˆ: "2024ë…„ 1ì›”~6ì›”: A, 2024ë…„ 7ì›”~í˜„ì¬: B")
- **ì—¬ëŸ¬ ì¦ê±°ê°€ ìˆëŠ” ê²½ìš°**: ê° ì¦ê±°ì˜ ì‹œì /ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ê³  ì¢…í•©í•˜ì—¬ ì„¤ëª…
- ë‹¨ìˆœíˆ ì´ë¦„, ìˆ«ìë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³  "ì–¸ì œ", "ì™œ", "ì–´ë–¤ ë§¥ë½ì—ì„œ" ë“±ì„ í•¨ê»˜ ì„¤ëª…

3. **ìš”ì•½** (Executive Summary)
- ë‹µë³€ ë‚´ìš©ì— ëŒ€í•œ ê°„ë‹¨í•œ ìš”ì•½
- êµ¬ì²´ì ì¸ ìˆ«ì, ë‚ ì§œ, ì¥ì†Œ, ì¸ë¬¼ ë“± í‚¤ì›Œë“œ í¬í•¨
- 3-5ë¬¸ì¥ ì´ë‚´ë¡œ ì••ì¶•"""

BLOCK_RESPONSE_FRAMEWORK = """## RESPONSE FRAMEWORK

**IMPORTANT ADDITION:** Summarize the answer in a short executive summary after giving the full structured response.

### Question Type Classification
Analyze the question and follow the appropriate path:

1. **Group-Based Analysis** (e.g., "ì§€ì—­ë³„ ë° ì—°ë ¹ë³„ ë¶„ì„")
- Generate blocks for EVERY group combination
- Maintain identical structure for each group
- Include ALL combinations without exception

2. **Ranking/Top-N Questions** (e.g., "ìƒìœ„ 10ê°œ ì œí’ˆ")
- Return EXACTLY N distinct items
- Provide unique insights for each item
- No duplicates unless explicitly different

3. **Summary/Trend Questions**
- Synthesize overall patterns
- Highlight key findings and anomalies

### Content Requirements

1. **Depth of Analysis**
- Psychological motivations behind behaviors
- Socio-cultural context and influences
- Real-world applications and scenarios
- Future implications and strategies

2. **Specificity Standards**
- Include concrete examples from data
- Provide actionable recommendations
- Connect insights to business impact

3. **Completeness Check**
- Address ALL parts of multi-part questions
- Include ALL requested group combinations
- Cover ALL data categories mentioned

4. **Avoid Contradictions/Inconsistencies**
- Ensure all statements maintain strict logical consistency throughout the response.
- Avoid self-contradictory or ironic phrasing. All parts of a statement, and statements within a paragraph or section, must align logically.
- **Example of what to avoid:** "Purchases of office supplies remain high, but interest in technology products is relatively low. They are likely to share information about simple technology usage related to daily life, health, or leisure activities." (This is contradictory: low interest in tech vs. high likelihood of sharing tech info.)
- If a nuance exists (e.g., low interest in *complex* tech vs. high interest in *simple, daily-life* tech), clarify it explicitly rather than stating a general contradiction.
"""


def _collect_image_uris_from_evidences(evidences: List[Evidence]) -> List[str]:
    """rag_evidencesì˜ metadataì—ì„œ image_base64ë¥¼ ì¶”ì¶œí•˜ì—¬ data URI ëª©ë¡ ìƒì„±"""
    image_uris: List[str] = []
    for ev in evidences or []:
        try:
            md = ev.metadata or {}
            b64 = md.get("image_base64")
            if isinstance(b64, str) and b64.strip():
                image_uris.append(f"data:image/png;base64,{b64}")
        except Exception:
            continue
    return image_uris


def _extract_conversation_history(state: GeneralAnswerState) -> str:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì¶”ì¶œí•˜ê³  ë‚´ë¶€ ì •ë³´ë¥¼ í•„í„°ë§"""
    recent_messages = []

    # ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡)
    for msg in state.messages[-8:]:
        if hasattr(msg, "content") and msg.content:
            msg_type = msg.__class__.__name__
            # ë‚´ìš©ì„ í•„í„°ë§ (contentê°€ listì¼ ìˆ˜ ìˆì–´ ë¬¸ìì—´í™”)
            sensitive_words = [r"superstore", r"\.csv\s*íŒŒì¼", r"\.xlsx?\s*íŒŒì¼"]
            sanitized_content = sanitize_content(
                content=str(msg.content),
                sensitive_words=sensitive_words,
                filter_word="data"
            )

            if msg_type == "HumanMessage":
                recent_messages.append(f"ğŸ‘¤ User: {sanitized_content}")
            elif msg_type == "AIMessage":
                recent_messages.append(f"ğŸ¤– AI: {sanitized_content}")

    return "\n".join(recent_messages) if recent_messages else "Conversation start"


def extract_synthesis_data(state: GeneralAnswerState) -> SynthesisData:
    """Stateì—ì„œ í•©ì„±ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œ"""
    # ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    # TODO: ì¿¼ë¦¬ë¥¼ ë­˜ ì‚¬ìš©í• ì§€ ê²°ì • í•„ìš”
    original_query = state.original_query or state.revised_query or ""
    current_instruction = state.current_instruction or ""

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ì¶œ
    conversation_history = _extract_conversation_history(state)

    # evidenceì—ì„œ ì´ë¯¸ì§€(data URI) ìˆ˜ì§‘
    rag_evidences: List[Evidence] = state.rag_evidences
    evidence_image_uris = _collect_image_uris_from_evidences(rag_evidences)

    return SynthesisData(
        original_query=original_query,
        revised_query=state.revised_query,
        current_instruction=current_instruction,
        rag_evidences=rag_evidences,
        analysis_results=state.analysis_results,
        visualization_results=state.visualization_results,
        ranked_candidates=state.ranked_candidates,
        forced_synthesis=state.forced_synthesis,
        conversation_history=conversation_history,
        formatted_text=state.formatted_context,
        image_base64_list=evidence_image_uris,
    )


def _format_evidence_content(
    evidences: List[Evidence], element_to_ref_map: Dict[str, str] | None = None
) -> str:
    """ì¦ê±° ë¦¬ìŠ¤íŠ¸ë¥¼ í¬ë§·íŒ…ëœ ë¬¸ìì—´ë¡œ ë³€í™˜.

    - element_to_ref_mapì´ ì£¼ì–´ì§€ë©´ ê° í•­ëª©ì— [ref:*] ë¼ë²¨ì„ ë¶€ì°©í•œë‹¤.
    - ref íƒœê·¸ê°€ ìˆëŠ” Evidenceë§Œ í¬í•¨í•˜ê³ , ref ë²ˆí˜¸ë¥¼ Evidence ë²ˆí˜¸ë¡œ ì‚¬ìš©í•œë‹¤.
    """
    lines: List[str] = []
    evidence_counter = 1  # ì‹¤ì œ í‘œì‹œë˜ëŠ” Evidence ë²ˆí˜¸
    
    for i, ev in enumerate(evidences):
        # source_idê°€ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ ì²« ë²ˆì§¸ í•­ëª©ì„ ì‚¬ìš© (ì„ì‹œ í˜¸í™˜ì„±)
        source_id = ev.source_id[0]['value'] if ev.source_id and len(ev.source_id) > 0 and 'value' in ev.source_id[0] else f"evidence_{i}"
        
        # ref íƒœê·¸ê°€ ìˆëŠ” Evidenceë§Œ í¬í•¨
        if element_to_ref_map and source_id in element_to_ref_map:
            ref_label = element_to_ref_map[source_id]  # ì˜ˆ: "ref:1"
            ref_number = ref_label.split(':')[1] if ':' in ref_label else str(evidence_counter)  # "1" ì¶”ì¶œ
            source_info = f"**ì¶œì²˜:** {ev.source}\n" if ev.source else ""
            # í•„ìš”ì‹œ ì£¼ì„ ì²˜ë¦¬ ì‰½ê²Œ: toc_title/toc_summaryë¥¼ Evidence í‘œì‹œë¬¸ì— í¬í•¨
            toc_info = ""
            if INCLUDE_TOC_CONTEXT:
                metadata = ev.metadata or {}
                payload = metadata.get("payload", {}) if isinstance(metadata.get("payload"), dict) else {}
                toc_title = ev.toc_title or payload.get("toc_title") or payload.get("section_title")
                toc_summary = ev.toc_summary or payload.get("toc_summary") or payload.get("section_summary")
                if toc_title or toc_summary:
                    toc_lines: List[str] = []
                    if toc_title:
                        toc_lines.append(f"TOC ì œëª©: {toc_title}")
                    if toc_summary:
                        toc_lines.append(f"TOC ìš”ì•½: {toc_summary}")
                    toc_info = "\n".join(toc_lines) + "\n"
            
            # ë¡œê¹…: Evidence ì¶œì²˜ ì •ë³´ í™•ì¸
            logger.info(f"[Evidence {ref_number}] source='{ev.source}' | relevance={ev.relevance_score:.2f} | content_preview={ev.content[:100]}...")
            
            lines.append(
                f"**{ref_number}. Evidence [{ref_label}]** (Relevance: {ev.relevance_score:.2f})\n{source_info}{toc_info}{ev.content}"
            )
            evidence_counter += 1
        else:
            # ref íƒœê·¸ê°€ ì—†ëŠ” EvidenceëŠ” ì œì™¸ (ë¡œê·¸ë§Œ ë‚¨ê¹€)
            logger.debug(f"[Evidence Skipped {i+1}] No ref mapping | source='{ev.source}' | relevance={ev.relevance_score:.2f}")
    
    formatted_result = "\n".join(lines)
    logger.debug(f"[Formatted Evidence] Total {len(lines)} items with refs:\n{formatted_result[:500]}...")
    return formatted_result

def _format_visualization_content(
    visualization_results: List[VisualizationResult],
) -> str:
    """ì‹œê°í™” ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ í¬ë§·íŒ…ëœ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    return "\n".join(
        [
            f"â€¢ {result.instruction} ({result.chart_type})"
            for result in visualization_results
        ]
    )


def _format_results_content(results: List[Any]) -> str:
    """ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ í¬ë§·íŒ…ëœ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    return "\n".join([f"â€¢ {result}" for result in results])


def _build_bounded_info_sections(
    evidences: List[Evidence], 
    max_tokens: int = 30000
) -> Tuple[List[str], List[str], Dict[str, str], Dict[str, Any]]:
    """
    Evidence ì „ìš© í† í° ì˜ˆì‚° ê´€ë¦¬ í•¨ìˆ˜ (ë²”ìš© í•¨ìˆ˜ ë˜í¼)
    
    Args:
        evidences: Evidence ë¦¬ìŠ¤íŠ¸
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
    
    Returns:
        (ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸, ì„ íƒëœ ID ë¦¬ìŠ¤íŠ¸, element_to_ref ë§¤í•‘, ref_to_element ë§¤í•‘)
    """
    # relevance_score ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ë†’ì€ relevance ìš°ì„  ì„ íƒ)
    sorted_evidences = sorted(
        evidences,
        key=lambda ev: ev.relevance_score,
        reverse=True
    )
    logger.info(f"[Evidence Sorting] Sorted {len(sorted_evidences)} evidences by relevance (desc)")
    if sorted_evidences:
        logger.info(f"  Top relevance: {sorted_evidences[0].relevance_score:.2f}, Bottom: {sorted_evidences[-1].relevance_score:.2f}")
    
    # ë²”ìš© í•¨ìˆ˜ í˜¸ì¶œì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ë“¤
    def content_getter(ev: Evidence) -> str:
        return ev.content or ""
    
    def id_getter(ev: Evidence) -> str:
        # source_idê°€ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ ì²« ë²ˆì§¸ í•­ëª©ì˜ valueë¥¼ ë°˜í™˜ (ref ë§¤í•‘ìš©)
        if ev.source_id and len(ev.source_id) > 0 and 'value' in ev.source_id[0]:
            return ev.source_id[0]['value']
        return ""
    
    def filter_func(ev: Evidence) -> bool:
        return ev.relevance_score >= CONFIG.RELEVANCE_SCORE_THRESHOLD
    
    def formatter(items: List[Evidence], ref_map: Dict[str, str]) -> str:
        return _format_evidence_content(items, ref_map)
    
    def full_id_getter(ev: Evidence) -> List[Dict[str, str]]:
        # ì „ì²´ source_id ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        return ev.source_id if ev.source_id else []
    
    # ë²”ìš© í•¨ìˆ˜ í˜¸ì¶œ (ì •ë ¬ëœ evidences ì‚¬ìš©)
    return build_bounded_info_sections(
        items=sorted_evidences,
        max_tokens=max_tokens,
        content_getter=content_getter,
        id_getter=id_getter,
        formatter=formatter,
        filter_func=filter_func,
        section_title="Bounded Analyzed Evidence",
        ref_prefix="ref",
        full_id_getter=full_id_getter
    )


def build_multimodal_evidence_images_message(
    evidences: List[Evidence], element_to_ref_map: Dict[str, str]
) -> Optional[HumanMessage]:
    """Evidence ë©”íƒ€ë°ì´í„°ì˜ ì´ë¯¸ì§€ë¥¼ ë©€í‹°ëª¨ë‹¬ ë©”ì‹œì§€ë¡œ êµ¬ì„±í•˜ë©° [ref:*] íƒœê·¸ë¥¼ í•¨ê»˜ í¬í•¨í•œë‹¤."""
    content_blocks: List[dict] = []
    for ev in evidences or []:
        try:
            md = ev.metadata or {}
            b64 = md.get("image_base64", md.get("properties", {}).get("image_base64", None))
            if not (isinstance(b64, str) and b64.strip()):
                continue
            source_id = str(ev.source_id or "")
            ref = element_to_ref_map.get(source_id)
            if ref:
                content_blocks.append({"type": "text", "text": f"Image {ref}"})
            url = f"data:image/png;base64,{b64}"
            content_blocks.append({"type": "image_url", "image_url": {"url": url}})
        except Exception:
            continue

    if not content_blocks:
        return None
    logger.debug("Multimodal evidence images: %d", len(content_blocks))
    return HumanMessage(content=content_blocks)  # type: ignore[arg-type]



async def build_prompt_from_blocks(
    data: SynthesisData,
    db: Optional[AsyncSession] = None,
    use_user_query_format: bool = False,
    info_sections: Optional[List[str]] = None
) -> str:
    """
    ë¸”ëŸ­ì„ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        data: í•©ì„± ë°ì´í„°
        db: DB ì„¸ì…˜ (ì„ íƒì )
        use_user_query_format: User Query Format ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, 5W1H ì‚¬ìš©)
        info_sections: ë¯¸ë¦¬ ê³„ì‚°ëœ ì •ë³´ ì„¹ì…˜ (ì„ íƒì ). Noneì´ë©´ ë‚´ë¶€ì—ì„œ ê³„ì‚°

    Returns:
        ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    # ì •ë³´ ì„¹ì…˜ êµ¬ì„± (ì „ë‹¬ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ê³„ì‚°)
    if info_sections is None:
        info_sections, _, _, _ = _build_bounded_info_sections(data.rag_evidences, max_tokens=8192)
    
    if data.analysis_results:
        analysis_content = _format_results_content(data.analysis_results)
        info_sections.append(f"**ğŸ“Š Data Analysis Results ({len(data.analysis_results)} items):**\n{analysis_content}")
    
    if data.visualization_results:
        visualization_content = _format_visualization_content(data.visualization_results)
        info_sections.append(f"**ğŸ“ˆ Visualization Results ({len(data.visualization_results)} items):**\n{visualization_content}")
    
    # ë¸”ëŸ­ êµ¬ì„±
    blocks = [
        {"type": "text", "content": BLOCK_BASE_INSTRUCTION},
        {
            "type": "text", 
            "content": f"""## TASK CONTEXT
**User Question (Original):** {data.original_query}
**User Question (Refined):** {data.revised_query}
**Supervisor Instruction:** {data.current_instruction}

## CONVERSATION HISTORY
{data.conversation_history}

## AVAILABLE INFORMATION
{chr(10).join(info_sections) if info_sections else 'No information collected.'}"""
        },
        {"type": "text", "content": BLOCK_CONFIDENTIALITY_RULES},
        {"type": "text", "content": BLOCK_RESPONSE_FRAMEWORK},  
    ]
    
    # ì¶œë ¥ êµ¬ì¡° ì„ íƒ
    if use_user_query_format:
        blocks.append({"type": "text", "content": BLOCK_OUTPUT_STRUCTURE_USER_QUERY_FORMAT})
    else:
        blocks.append({"type": "text", "content": BLOCK_OUTPUT_STRUCTURE_5W1H})
    
    # ëª¨ë“œë³„ ì§€ì¹¨
    mode_text = "**âš ï¸ Limited Information Mode**: Work only with available verified facts. State limitations clearly." if data.forced_synthesis else "**âœ… Sufficient Information Mode**: Utilize all collected information comprehensively."
    blocks.append({"type": "text", "content": f"## MODE-SPECIFIC GUIDANCE\n{mode_text}"})
    
    blocks.append({"type": "text", "content": BLOCK_FINAL_CHECKLIST})
    
    # ì¦ê±°ê°€ ìˆìœ¼ë©´ ì¸ìš© ì§€ì¹¨ ì¶”ê°€
    if data.rag_evidences:
        blocks.append({"type": "text", "content": BLOCK_CITATION_WITH_REF})
    
    blocks.append({"type": "text", "content": "\n<|assistant|>\në¶„ì„ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."})
    
    # ë Œë”ë§
    return await render_blocks_to_string(blocks, {}, db)


async def get_system_prompt_and_collect_ids(data: SynthesisData) -> Tuple[SystemMessage, List[str], Dict[str, str], Dict[str, Any]]:
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)

    ë¸”ëŸ­ ê¸°ë°˜ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    # í† í° ì˜ˆì‚° ë‚´ ì •ë³´ ì„¹ì…˜ êµ¬ì„± (Evidence) - IDs ìˆ˜ì§‘ìš© (í•œ ë²ˆë§Œ í˜¸ì¶œ)
    info_sections, used_evidence_ids, element_to_ref_map, ref_to_element_map = _build_bounded_info_sections(data.rag_evidences, max_tokens=8192)

    # ë¸”ëŸ­ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ ê³„ì‚°ëœ info_sections ì „ë‹¬)
    prompt_content = await build_prompt_from_blocks(data, db=None, info_sections=info_sections)
    system_prompt = SystemMessage(content=f"<|system|>\n{prompt_content}")

    return system_prompt, used_evidence_ids, element_to_ref_map, ref_to_element_map

async def get_system_prompt_user_query_format_and_collect_ids(data: SynthesisData) -> Tuple[SystemMessage, List[str], Dict[str, str], Dict[str, Any]]:
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„± (User Query Format) - ë¸”ëŸ­ ê¸°ë°˜

    ìœ ì €ì˜ ì§ˆë¬¸ í˜•ì‹ì— ë§ì¶° ë‹µë³€í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # í† í° ì˜ˆì‚° ë‚´ ì •ë³´ ì„¹ì…˜ êµ¬ì„± (Evidence) - IDs ìˆ˜ì§‘ìš© (í•œ ë²ˆë§Œ í˜¸ì¶œ)
    info_sections, used_evidence_ids, element_to_ref_map, ref_to_element_map = _build_bounded_info_sections(data.rag_evidences, max_tokens=8192)

    # ë¸”ëŸ­ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ ê³„ì‚°ëœ info_sections ì „ë‹¬)
    prompt_content = await build_prompt_from_blocks(data, db=None, use_user_query_format=True, info_sections=info_sections)
    system_prompt = SystemMessage(content=f"<|system|>\n{prompt_content}")

    return system_prompt, used_evidence_ids, element_to_ref_map, ref_to_element_map
