from pydantic import BaseModel, ConfigDict, Field
from typing import Optional, Tuple, Dict, List, Annotated, Union, Any
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
import pandas as pd


def merge_list(left: Optional[List[Any]], right: Optional[List[Any]]) -> List[Any]:
    if left == right:
        return left or []
    return (left or []) + (right or [])


class MappedKeyword(BaseModel):
    raw_keyword: str
    mapped_keyword: str
    confidence: float


class UnmappedKeyword(BaseModel):
    raw_keyword: str
    candidate_entities: List[str]
    confidences: List[float]


class CandidateChunk(BaseModel):
    element_id: str
    chunk_type: str  # "keyword", "fact", "section"
    collection_name: str
    content: str
    confidence: float
    metadata: Dict[str, Any] = Field(default_factory=dict)


class MergedCandidate(BaseModel):
    """Vector/Graph ë³‘í•© ê²°ê³¼ì˜ í‘œì¤€ ìŠ¤í‚¤ë§ˆ"""

    id: str
    labels: List[str] = Field(default_factory=list)
    type: Optional[str] = None
    content: str = ""
    weight: float = 0.0
    confidence: float = 0.0
    connections: int = 0
    sources: List[str] = Field(default_factory=list)
    section_id: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)
    # ê´€ê³„ëŠ” í˜„ì¬ dict ê¸°ë°˜ìœ¼ë¡œ ìœ ì§€ (ê¸°ì¡´ ìœ í‹¸ê³¼ì˜ í˜¸í™˜ì„±)
    relation: List[Dict[str, Any]] = Field(default_factory=list)
    # ì´ë¯¸ì§€ ê´€ë ¨(ì˜µì…˜)
    image_base64: Optional[str] = None
    images: Optional[Dict[str, Any]] = None

class Candidate(BaseModel):
    "graph ê²°ê³¼"
    # dict í˜•íƒœì˜ ê²°ê³¼
    result : Optional[Dict[str, Any]] # Neo4j ì¿¼ë¦¬ return ê°’
    # resultë¥¼ íŒŒì‹±í•´ì„œ contentì— ì €ì¥ (ì´ë¯¸ì§€ ë°ì´í„° ì œì™¸)
    content  : str
    source : List[Dict[str, Any]] = Field(default_factory=list) # result ì •ë³´ ì¤‘ _idë¡œ ë‚˜íƒ€ë‚´ì–´ì§€ëŠ” source ì •ë³´ ëª¨ìŒ
    # ì´ë¯¸ì§€ ì²˜ë¦¬
    image_base64 : List[str] = Field(default_factory=list) # ì¶”ì¶œëœ ì´ë¯¸ì§€ base64 ë¦¬ìŠ¤íŠ¸
    is_image : bool = Field(default=False) # ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€
    # ì´ ê²°ê³¼ë¥¼ ì–»ëŠ”ë° ì‚¬ìš©í•œ Cypher ì¿¼ë¦¬
    cypher_query : Optional[str] = None
    
class CypherQuery(BaseModel):
    cypher_query: str
    schema_info: str
    success: Optional[bool] = None
    error: Optional[str] = None
    reuse: Optional[bool] = None
    params: Optional[Dict[str, Any]] = None  # Cypher ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
class CollectionWeights(BaseModel):
    keyword_weight: float = 1.0
    fact_weight: float = 0.8
    section_weight: float = 0.6

    def normalize_weights(self) -> "CollectionWeights":
        """ê°€ì¤‘ì¹˜ ì •ê·œí™”"""
        total = self.keyword_weight + self.fact_weight + self.section_weight
        if total == 0:
            return CollectionWeights()
        return CollectionWeights(
            keyword_weight=self.keyword_weight / total,
            fact_weight=self.fact_weight / total,
            section_weight=self.section_weight / total,
        )


class UnifiedRAGState(BaseModel):
    # === ì…ë ¥ ë°ì´í„° ===
    model_config = ConfigDict(arbitrary_types_allowed=True)

    original_query: str
    revised_query: Optional[str] = None
    retrieved_contexts: Optional[List[str]] = None
    raw_keywords: Optional[List[str]] = None
    selected_document_ids: Optional[List[str]] = None
    selected_storage_paths: Optional[List[str]] = None
    auto_selected_folders: Optional[List[str]] = None
    select_all_requested: bool = False
    auto_select_requested: bool = False
    auto_select_threshold: int = 100
    selection_reason: Optional[str] = None
    hidden_prompt_ids: Optional[List[str]] = None
    hidden_prompts: Optional[List[str]] = None
    combined_hidden_prompt: Optional[str] = None

    conversation_classification: Optional[Dict[str, Any]] = None

    # Intent ë¼ìš°íŒ… ê´€ë ¨ í•„ë“œ
    intent_query_type: Optional[str] = None  # "DOCUMENT_OVERVIEW", "COMPARISON", "DETAIL_SEARCH"
    needs_clarification: bool = Field(default=False)  # clarification ì‘ë‹µ í•„ìš” ì—¬ë¶€
    clarification_message: Optional[str] = None  # clarification ë©”ì‹œì§€
    suggested_document: Optional[Dict[str, Any]] = None  # ì œì•ˆëœ ë¬¸ì„œ ì •ë³´
    conversation_skipped: bool = Field(default=False)  # ëŒ€í™” ìŠ¤í‚µ ì—¬ë¶€ (CASUAL ë˜ëŠ” clarification)

    keyword_mapping_results: Optional[Dict[str, List[str]]] = None
    canonical_mapping_results: Optional[Dict[str, List[str]]] = None

    # === Vector Search ê²°ê³¼ (ì»¬ë ‰ì…˜ë³„) ===
    keyword_candidates: List[CandidateChunk] = Field(default_factory=list)
    fact_candidates: List[CandidateChunk] = Field(default_factory=list)
    section_candidates: List[CandidateChunk] = Field(default_factory=list)
    candidate_chunks: List[CandidateChunk] = Field(default_factory=list)

    # === Graph Search ê²°ê³¼ ===
    cypher_group: Optional[List[str]] = None
    cypher_fewshot: Optional[List[str]] = None
    cypher_query: Annotated[
        Optional[List[CypherQuery]], lambda x, y: (x or []) + (y or [])
    ] = None
    records: Annotated[
        Optional[List[Dict[str, Any]]], lambda x, y: (x or []) + (y or [])
    ] = None
    expanded_candidates: List[CandidateChunk] = Field(default_factory=list)

    # === Merge Search ê²°ê³¼ ===
    merged_candidates: List[MergedCandidate] = Field(default_factory=list)

    # === ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ ===
    ranked_candidates: List[CandidateChunk] = Field(default_factory=list)
    formatted_context: Optional[str] = None
    
    candidate_group : List[Candidate] = Field(default_factory=list) # ê²€ìƒ‰ëœ ì •ë³´
    # ì €ì¥ìš© ì»¨í…ìŠ¤íŠ¸(ì´ë¯¸ì§€ data URIë¥¼ [Image]ë¡œ ì¹˜í™˜í•œ ë§ˆí¬ë‹¤ìš´)
    save_context: Optional[str] = None
    final_answer: Optional[str] = None
    # synthesizer outputs for traceability
    used_evidence_ids: List[str] = Field(default_factory=list)
    used_candidate_ids: List[str] = Field(default_factory=list)  # unused
    element_to_ref_map: Optional[Dict[str, Any]] = None # ref:1ì— ì¶œì²˜ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš°ì—ëŠ” listí˜•íƒœë¡œ ì €ì¥ë¨, list[dict[str, str]]
    ref_to_element_map: Optional[Dict[str, str]] = None
    # mapping for batch evidences to child candidate IDs
    batch_children_map: Dict[str, List[str]] = Field(default_factory=dict)  # unused

    # === ë©”íƒ€ë°ì´í„° ===
    search_metadata: Dict[str, Any] = Field(default_factory=dict)
    tool_logs: List[str] = Field(default_factory=list)

    # === ë°ì´í„° ê´€ë ¨ ===
    data: Optional[Dict[str, Union[pd.DataFrame, Dict[str, Any]]]] = Field(default=None)
    
    # === ì‹œê°í™” ê²°ê³¼ (GeneralAnswerStateì™€ í˜¸í™˜) ===
    visualization_results: Annotated[
        List["VisualizationResult"], lambda x, y: (x or []) + (y or [])
    ] = Field(default_factory=list)

    # === ì„ì‹œ í‚¤ê°’ ===
    messages: Annotated[List[BaseMessage], add_messages] = Field(default_factory=list)

    def get_all_vector_candidates(self) -> List[CandidateChunk]:
        """ëª¨ë“  ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ í†µí•©"""
        return self.keyword_candidates + self.fact_candidates + self.section_candidates

    def get_weighted_candidates(
        self, weights: CollectionWeights
    ) -> List[CandidateChunk]:
        """ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ í›„ë³´ í†µí•©"""
        weighted_candidates = []

        # ê° collectionë³„ë¡œ ê°€ì¤‘ì¹˜ ì ìš©
        for candidate in self.keyword_candidates:
            weighted_candidate = candidate.copy()
            weighted_candidate.confidence *= weights.keyword_weight
            weighted_candidate.metadata["original_confidence"] = candidate.confidence
            weighted_candidate.metadata["collection_weight"] = weights.keyword_weight
            weighted_candidates.append(weighted_candidate)

        for candidate in self.fact_candidates:
            weighted_candidate = candidate.copy()
            weighted_candidate.confidence *= weights.fact_weight
            weighted_candidate.metadata["original_confidence"] = candidate.confidence
            weighted_candidate.metadata["collection_weight"] = weights.fact_weight
            weighted_candidates.append(weighted_candidate)

        for candidate in self.section_candidates:
            weighted_candidate = candidate.copy()
            weighted_candidate.confidence *= weights.section_weight
            weighted_candidate.metadata["original_confidence"] = candidate.confidence
            weighted_candidate.metadata["collection_weight"] = weights.section_weight
            weighted_candidates.append(weighted_candidate)

        # confidence ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        return sorted(weighted_candidates, key=lambda x: x.confidence, reverse=True)

    def get_candidates_by_type(self, chunk_type: str) -> List[CandidateChunk]:
        """íƒ€ì…ë³„ í›„ë³´ ì¶”ì¶œ"""
        return [
            c for c in self.get_all_vector_candidates() if c.chunk_type == chunk_type
        ]

    # === ì¬ìƒì„± ê´€ë ¨ í•„ë“œ ===
    cypher_regeneration_count: int = Field(default=0, description="Cypher ì¿¼ë¦¬ ì¬ìƒì„± íšŸìˆ˜")
    max_regeneration_attempts: int = Field(default=1, description="ìµœëŒ€ ì¬ìƒì„± ì‹œë„ íšŸìˆ˜")

    def get_element_ids(self) -> List[str]:
        """ëª¨ë“  í›„ë³´ì˜ element_id ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        all_candidates = (
            self.get_all_vector_candidates()
            + self.expanded_candidates
            + self.ranked_candidates
        )
        return list(set([c.element_id for c in all_candidates]))


class Evidence(BaseModel):
    """ë¶„ì„ì„ í†µí•´ ì¶”ì¶œí•œ í•µì‹¬ ì¦ê±° ì •ë³´"""

    source: str = Field(description="ì¦ê±° ì¶œì²˜ (ë¬¸ì„œëª…, ì²­í¬ID ë“±)")
    content: str = Field(description="í•µì‹¬ ì¦ê±° ë‚´ìš© (ìš”ì•½ ë˜ëŠ” í•µì‹¬ í¬ì¸íŠ¸)")
    relevance_score: float = Field(description="ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„± ì ìˆ˜ (0.0-1.0)")
    source_id: List[Dict[str, str]] = Field(default_factory=list, description="ì›ë³¸ ì¶œì²˜ ID ëª©ë¡ (ì²­í¬/ì„¹ì…˜/ê¸°íƒ€)")
    evidence_type: str = Field(
        default="rag", description="ì¦ê±° íƒ€ì… (rag, web, analysis ë“±)"
    )
    toc_title: Optional[str] = Field(
        default=None, description="(ì˜µì…˜) ì—°ê²°ëœ TOC/ì„¹ì…˜ ì œëª©"
    )
    toc_summary: Optional[str] = Field(
        default=None, description="(ì˜µì…˜) ì—°ê²°ëœ TOC ìš”ì•½/ì„¤ëª…"
    )
    metadata: Dict[str, Any] = Field(
        default_factory=dict, description="ì›ë³¸ í›„ë³´ ë©”íƒ€ë°ì´í„° (traceability)"
    )


class VisualizationResult(BaseModel):
    """ì‹œê°í™” ê²°ê³¼"""

    image_path: str = Field(description="ì´ë¯¸ì§€ ê²½ë¡œ")
    instruction: str = Field(description="ì‚¬ìš©ì ìš”ì²­")
    chart_created: bool = Field(description="ì°¨íŠ¸ ìƒì„± ì—¬ë¶€")
    base64_image: str = Field(description="ì´ë¯¸ì§€ Base64 ì¸ì½”ë”©")
    timestamp: str = Field(description="ìƒì„± ì‹œê°„")
    chart_type: str = Field(description="ì°¨íŠ¸ íƒ€ì…")


class GeneralAnswerState(BaseModel):
    """ë²”ìš© ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í™•ì¥ëœ State"""

    model_config = ConfigDict(arbitrary_types_allowed=True)

    # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥
    # RAG Stateì™€ ê³µìœ ë˜ëŠ” í•„ë“œ
    original_query: str
    revised_query: Optional[str] = None
    formatted_context: Optional[str] = None
    # ì €ì¥ìš© ì»¨í…ìŠ¤íŠ¸(ì´ë¯¸ì§€ data URIë¥¼ [Image]ë¡œ ì¹˜í™˜í•œ ë§ˆí¬ë‹¤ìš´)
    save_context: Optional[str] = None

    # ê¸°ë³¸ ë©”ì‹œì§€ ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
    messages: Annotated[List[BaseMessage], add_messages]
    next_node: Optional[str] = None
    current_instruction: Optional[str] = None

    # ìŠ¤í… ì œí•œ (ë¬´í•œ ë°˜ë³µ ë°©ì§€)
    current_step: int = Field(default=0)
    max_steps: int = Field(default=20)

    # ì •ë³´ ìˆ˜ì§‘ ì‹œë„ ê´€ë¦¬
    rag_analysis_attempts: int = Field(default=0)
    max_search_attempts: int = Field(default=2, description="ê° íƒ€ì…ë³„ ìµœëŒ€ ì‹œë„ íšŸìˆ˜")

    # ë°ì´í„° ê´€ë ¨ (í†µê³„ ë¶„ì„ìš©)
    data: Optional[Dict[str, Union[pd.DataFrame, Dict[str, Any]]]] = None
    images: Annotated[List[str], merge_list] = Field(default_factory=list)
    analysis_results: Annotated[List[Dict[str, Any]], merge_list] = Field(
        default_factory=list
    )
    visualization_results: Annotated[List[VisualizationResult], merge_list] = Field(
        default_factory=list
    )

    # RAG ê´€ë ¨ (UnifiedRAGStateì™€ í˜¸í™˜)
    ranked_candidates: Annotated[List[CandidateChunk], merge_list] = Field(
        default_factory=list, description="ìµœì¢… ì²˜ë¦¬ëœ RAG í›„ë³´ë“¤ (UnifiedRAGStateì™€ ê³µìœ )"
    )
    # ìƒˆë¡œìš´ ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°
    candidate_group: List[Candidate] = Field(default_factory=list, description="ê²€ìƒ‰ëœ ì •ë³´ (ìƒˆë¡œìš´ êµ¬ì¡°)")
    rag_evidences: Annotated[List[Evidence], merge_list] = Field(
        default_factory=list, description="RAGì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ì¦ê±°ë“¤"
    )
    rag_analysis_done: bool = Field(default=False)

    forced_synthesis: bool = Field(default=False, description="ì •ë³´ ë¶€ì¡±í•˜ì§€ë§Œ ê°•ì œ ë‹µë³€ ëª¨ë“œ")

    # ê¸°íƒ€ ê²€ìƒ‰ ê²°ê³¼
    search_results: Annotated[List[Dict[str, Any]], merge_list] = Field(
        default_factory=list, description="ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë“¤"
    )

    # ì‘ì—… íˆìŠ¤í† ë¦¬ ë° ë¡œê·¸
    operation_history: Annotated[List[str], merge_list] = Field(default_factory=list)
    tool_logs: Annotated[List[str], merge_list] = Field(default_factory=list)

    # ìµœì¢… ë‹µë³€ ê´€ë ¨
    final_answer: Optional[str] = None
    # synthesizer outputs for traceability
    used_evidence_ids: Annotated[List[str], merge_list] = Field(default_factory=list)
    element_to_ref_map: Optional[Dict[str, Any]] = None # ref:1ì— ì¶œì²˜ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš°ì—ëŠ” listí˜•íƒœë¡œ ì €ì¥ë¨, list[dict[str, str]]
    ref_to_element_map: Optional[Dict[str, str]] = None


class DataAnalysisReActState(BaseModel):
    """ReAct ë°ì´í„° ë¶„ì„ ì „ìš© ìƒíƒœ - GeneralAnswerStateì™€ ë…ë¦½"""

    model_config = ConfigDict(arbitrary_types_allowed=True)

    # ğŸ”— í˜¸í™˜ì„± í‚¤ë“¤ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì—°ë™ìš©)
    messages: Annotated[List[BaseMessage], add_messages] = Field(
        default_factory=list
    )  # ìŠˆí¼ë°”ì´ì €ì™€ ê³µìœ ë˜ëŠ” ë©”ì„¸ì§€ (final_answerë§Œ ì €ì¥)

    data: Optional[Dict[str, pd.DataFrame]] = Field(default=None)
    analysis_results: Annotated[
        List[Dict[str, Any]], lambda x, y: (x or []) + (y or [])
    ] = Field(default_factory=list)
    # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥
    revised_query: Optional[str] = None

    # ----------------------------------------------------------------

    # ğŸ¤– ReAct ë‚´ë¶€ ë©”ì‹œì§€ ê´€ë¦¬ (ìŠˆí¼ë°”ì´ì €ì™€ ë¶„ë¦¬)
    react_messages: Annotated[List[BaseMessage], add_messages] = Field(
        default_factory=list, description="ReAct ê³¼ì •ì˜ ë‚´ë¶€ ë©”ì‹œì§€ë“¤"
    )

    # ğŸ¯ ReAct ì „ìš© í•„ë“œë“¤
    current_instruction: str = Field(description="í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ ì‘ì—… ì§€ì‹œ")

    # ReAct ì‚¬ì´í´ ê´€ë¦¬
    current_iteration: int = Field(default=0)
    max_iterations: int = Field(default=20)

    # í˜„ì¬ ì§„í–‰ ìƒíƒœ
    current_thought: Optional[str] = None
    current_action: Optional[str] = None
    current_action_input: Optional[Any] = None
    current_observation: Optional[str] = None

    # ë„êµ¬ ê´€ë ¨
    tool_execution_history: Annotated[
        List[Dict[str, Any]], lambda x, y: (x or []) + (y or [])
    ] = Field(default_factory=list)

    # ì™„ë£Œ ìƒíƒœ
    task_completed: bool = Field(default=False)
    final_answer: Optional[str] = None
    completion_reason: Optional[str] = None  # "success", "max_iterations", "error"

    # ì˜¤ë¥˜ ì²˜ë¦¬
    last_error: Optional[str] = None
    error_count: int = Field(default=0)
    max_errors: int = Field(default=10)

    # ğŸ†• í…ìŠ¤íŠ¸ ë¶„ì„ ê´€ë ¨ í•„ë“œë“¤
    text_candidate_chunks: Annotated[
        List[CandidateChunk], lambda x, y: (x or []) + (y or [])
    ] = Field(default_factory=list, description="ë°ì´í„°í”„ë ˆì„ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ CandidateChunkë“¤")
    rag_evidences: Annotated[
        List[Evidence], lambda x, y: (x or []) + (y or [])
    ] = Field(
        default_factory=list,
        description="RAG analyzerë¡œë¶€í„° ë°›ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ (GeneralAnswerStateì™€ í‚¤ ê³µìœ )",
    )
    requires_text_analysis: bool = Field(default=False, description="í…ìŠ¤íŠ¸ ë¶„ì„ì´ í•„ìš”í•œì§€ ì—¬ë¶€")
    text_analysis_completed: bool = Field(default=False, description="í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ ì—¬ë¶€")


class VisualizationReActState(BaseModel):
    """ì‹œê°í™” ReAct ì „ìš© ìƒíƒœ - GeneralAnswerStateì™€ ë…ë¦½ì ì¸ ë‚´ë¶€ ìƒíƒœ ê´€ë¦¬"""

    model_config = ConfigDict(arbitrary_types_allowed=True)

    # ğŸ”— Supervisor ê³µìœ  ì˜ì—­ (GeneralAnswerStateì™€ í˜¸í™˜)
    messages: Annotated[List[BaseMessage], add_messages] = Field(default_factory=list)
    data: Optional[Dict[str, pd.DataFrame]] = Field(default=None)
    visualization_results: Annotated[
        List[VisualizationResult], lambda x, y: (x or []) + (y or [])
    ] = Field(default_factory=list)
    images: Annotated[List[str], lambda x, y: (x or []) + (y or [])] = Field(
        default_factory=list
    )
    # ğŸ¤– ReAct ë‚´ë¶€ ë©”ì‹œì§€ ê´€ë¦¬ (ìŠˆí¼ë°”ì´ì €ì™€ ë¶„ë¦¬)
    react_messages: Annotated[List[BaseMessage], add_messages] = Field(
        default_factory=list, description="ReAct ê³¼ì •ì˜ ë‚´ë¶€ ë©”ì‹œì§€ë“¤"
    )

    # ğŸ¯ ReAct ì „ìš© í•„ë“œë“¤
    current_instruction: str = Field(description="í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ ì‹œê°í™” ì§€ì‹œ")
    revised_query: Optional[str] = Field(default=None, description="ìˆ˜ì •ëœ ì¿¼ë¦¬")

    # ReAct ì‚¬ì´í´ ê´€ë¦¬
    current_iteration: int = Field(default=0)
    max_iterations: int = Field(default=20)

    # í˜„ì¬ ì§„í–‰ ìƒíƒœ
    current_thought: Optional[str] = None
    current_action: Optional[str] = None
    current_action_input: Optional[Any] = None
    current_observation: Optional[str] = None

    # ì‹œê°í™” ì „ìš© í•„ë“œë“¤
    generated_image_paths: List[str] = Field(default_factory=list)
    successful_charts: int = Field(default=0)
    failed_charts: int = Field(default=0)

    # ë„êµ¬ ê´€ë ¨
    tool_execution_history: Annotated[
        List[Dict[str, Any]], lambda x, y: (x or []) + (y or [])
    ] = Field(default_factory=list)

    # ì™„ë£Œ ìƒíƒœ
    task_completed: bool = Field(default=False)
    final_answer: Optional[str] = None
    completion_reason: Optional[str] = None  # "success", "max_iterations", "error"

    # ì˜¤ë¥˜ ì²˜ë¦¬
    last_error: Optional[str] = None
    error_count: int = Field(default=0)
    max_errors: int = Field(default=10)
