"""
2025/11/11 kimgeonwoo
ë‹µë³€ ì‹œ candidate í˜•íƒœì˜ ë°ì´í„° ì¶”ê°€
"""
import logging
import asyncio
from typing import Dict, Any, List, Optional, cast, Callable

from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnableConfig


from shared.config.config import llm_config
from shared.factory.llm_factory import get_llm
from rag.graph.progress import send_progress
from shared.utils.logging import (
    wrap_long_text, 
    log_section, 
    log_step, 
    log_data
)

from .prompts import get_system_prompt, get_batch_prompt, get_batch_prompt_for_candidates
from .validation import validate_input_data
from .response_formats import (
    create_no_candidates_response, 
    create_success_response, 
    create_error_response, 
    synthesize_analysis_from_evidences
)
from .models import BatchEvidenceLLMResult
from .utils import group_candidates_into_batches, map_ref_id_to_element_id
from rag.schemas.types import (
    GeneralAnswerState,
    Evidence,
    CandidateChunk,
    Candidate,
)

logger = logging.getLogger(__name__)


def _find_toc_title_from_relations(relations: Any) -> Optional[str]:
    """TOC-Section ê´€ê³„ ì •ë³´ì—ì„œ toc titleì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í—¬í¼"""
    try:
        if not isinstance(relations, list):
            return None
        for rel in relations:
            if not isinstance(rel, dict):
                continue
            # ëª…ì‹œì  í•„ë“œ ìš°ì„ 
            toc_title = rel.get("toc_title") or rel.get("tocTitle")
            if toc_title:
                return toc_title
            # ë…¸ë“œ ì •ë³´ì— TOC ë¼ë²¨ì´ ìˆëŠ” ê²½ìš° title/name ì‚¬ìš©
            for node_key in ("start_node", "end_node", "start", "end"):
                node = rel.get(node_key)
                if not isinstance(node, dict):
                    continue
                labels = []
                if isinstance(node.get("labels"), list):
                    labels = [str(lbl).lower() for lbl in node.get("labels")]
                node_type = str(node.get("type", "")).lower()
                is_toc = "toc" in labels or node_type == "toc"
                if is_toc:
                    title = node.get("title") or node.get("name")
                    if title:
                        return title
    except Exception:
        return None
    return None


def _extract_toc_title(metadata: Dict[str, Any], candidate_result: Optional[Dict[str, Any]] = None, fallback_section_title: Optional[str] = None) -> Optional[str]:
    """payloadë‚˜ ê´€ê³„ ì •ë³´ì—ì„œ toc_titleì„ ìµœëŒ€í•œ ì¶”ì¶œ (ì—†ìœ¼ë©´ ì„¹ì…˜ ì œëª©ìœ¼ë¡œ í´ë°±)"""
    try:
        # 1) payload ê¸°ì¤€ ì§ì ‘ í•„ë“œ
        payload = metadata.get("payload") if isinstance(metadata.get("payload"), dict) else {}
        toc_title = None
        if isinstance(payload, dict):
            toc_title = (
                payload.get("toc_title")
                or payload.get("tocTitle")
                or (isinstance(payload.get("toc"), dict) and payload.get("toc", {}).get("title"))
            )
            if not toc_title:
                toc_title = _find_toc_title_from_relations(
                    payload.get("relations") or payload.get("relationships")
                )
        # 2) ë©”íƒ€ë°ì´í„° ë£¨íŠ¸ì—ì„œë„ íƒìƒ‰
        if not toc_title and isinstance(metadata, dict):
            toc_title = (
                metadata.get("toc_title")
                or metadata.get("tocTitle")
                or (isinstance(metadata.get("toc"), dict) and metadata.get("toc", {}).get("title"))
            )
            if not toc_title:
                toc_title = _find_toc_title_from_relations(
                    metadata.get("relations") or metadata.get("relationships")
                )
        # 3) candidate.result ë‚´ë¶€ contextì—ì„œ íƒìƒ‰ (ê·¸ë˜í”„ ê²°ê³¼ìš©)
        if not toc_title and isinstance(candidate_result, dict):
            toc_title = candidate_result.get("toc_title")
            if not toc_title:
                toc_title = _find_toc_title_from_relations(
                    candidate_result.get("relations") or candidate_result.get("relationships")
                )
            if not toc_title:
                contexts = candidate_result.get("context_sections")
                if isinstance(contexts, list):
                    for ctx in contexts:
                        if isinstance(ctx, dict) and ctx.get("toc_title"):
                            toc_title = ctx.get("toc_title")
                            break
        return toc_title or fallback_section_title
    except Exception:
        return fallback_section_title
async def generate_evidences_for_batch(
    batch: List[CandidateChunk], batch_id: str, query: str
) -> List[Evidence]:
    """ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ë°°ì¹˜ ë‚´ ê° í›„ë³´ì— ëŒ€í•œ Evidenceë¥¼ ì§ì ‘ ìƒì„±í•œë‹¤."""
    try:
        llm = get_llm(llm_config)
        structured_llm = llm.with_structured_output(BatchEvidenceLLMResult)
        # ref ë§¤í•‘
        ref_to_id = {f"ref:{idx}": candidate.element_id for idx, candidate in enumerate(batch)}
        id_to_ref = {v: k for k, v in ref_to_id.items()}

        batch_messages = get_batch_prompt(batch, query, id_to_ref)
        system_text = await get_system_prompt()

        messages: List[Any] = [
            SystemMessage(content=system_text),
            *batch_messages,
        ]

        try:
            result: BatchEvidenceLLMResult = cast(BatchEvidenceLLMResult, await structured_llm.ainvoke(messages))
            if len(result.candidate_evidences) > len(batch):
                logger.warning(
                    f"{batch_id} [EVID] LLM returned more items than inputs: outputs={len(result.candidate_evidences)}, inputs={len(batch)}"
                )
        except Exception as llm_error:
            logger.error(f"{batch_id} [EVID] LLM API call failed: {llm_error}")
            return []

        # ê²°ê³¼ë¥¼ Evidenceë¡œ ë³€í™˜ (ref -> element_id)
        valid_element_ids = {str(c.element_id) for c in batch}
        candidate_map = {c.element_id: c for c in batch}
        evidences: List[Evidence] = []

        for item in result.candidate_evidences:
            element_id = map_ref_id_to_element_id(item.candidate_id, ref_to_id, valid_element_ids)
            if not element_id:
                continue
            candidate = candidate_map.get(element_id)
            if not candidate:
                continue
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ë¬¸ì„œ ì œëª© ë° ì„¹ì…˜ ì œëª© ì¶”ì¶œ
            metadata = candidate.metadata or {}
            doc_title = None
            section_title = None
            toc_summary = None
            
            # 1) Qdrant payloadì—ì„œ ì •ë³´ ì¶”ì¶œ (ë²¡í„° ê²€ìƒ‰ ê²°ê³¼)
            if isinstance(metadata.get("payload"), dict):
                payload = metadata["payload"]
                doc_title = payload.get("document_title") or payload.get("doc_title")
                section_title = _extract_toc_title(metadata, fallback_section_title=payload.get("section_title"))
                toc_summary = payload.get("toc_summary") or payload.get("section_summary")
                logger.debug(
                    "[Evidence Payload] element_id=%s | toc_title=%s | toc_summary=%s",
                    element_id,
                    section_title,
                    toc_summary,
                )
            
            # 2) element_idì—ì„œ ë¬¸ì„œëª… ì¶”ì¶œ (ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼)
            # Neo4j Section/Fact/Table ë…¸ë“œì—ëŠ” document_titleì´ ì—†ìœ¼ë¯€ë¡œ element_idì—ì„œ íŒŒì‹±
            if not doc_title:
                try:
                    # Section/Fact: "ë¬¸ì„œëª…_toc_XXX_sec_YYY" í˜•ì‹
                    if "_toc_" in element_id:
                        doc_title = element_id.split("_toc_")[0]
                    # Table/Image: "ë¬¸ì„œëª…_page_N_table_M" í˜•ì‹
                    elif "_page_" in element_id:
                        doc_title = element_id.split("_page_")[0]
                except Exception:
                    pass
            
            # source êµ¬ì„±: ë¬¸ì„œëª…ê³¼ ì„¹ì…˜ëª…ì„ í•¨ê»˜ í‘œì‹œ
            if doc_title and section_title:
                source = f"{doc_title} > {section_title} ({candidate.chunk_type})"
            elif doc_title:
                source = f"{doc_title} ({candidate.chunk_type})"
            else:
                source = f"{candidate.collection_name} - {candidate.chunk_type}"
            
            # ë¡œê¹…: Evidence source ìƒì„± ì •ë³´
            logger.info(
                "[Evidence Created] element_id=%s | doc_title='%s' | section_title='%s' | toc_summary_preview='%s' | final_source='%s'",
                element_id,
                doc_title,
                section_title,
                (toc_summary or "")[:80],
                source,
            )
            
            evidences.append(
                Evidence(
                    source=source,
                    content=item.evidence,
                    relevance_score=item.relevance_score,
                    source_id=[{"key": "element_id", "value": element_id}],
                    evidence_type="rag_extracted",
                    toc_title=section_title,
                    toc_summary=toc_summary,
                    metadata=metadata,
                )
            )

        return evidences

    except Exception as e:
        logger.error(f"{batch_id} [EVID] unexpected error: {e}", exc_info=True)
        return []


async def generate_evidences_for_candidate_batch(
    batch: List[Candidate], batch_id: str, query: str, revised_query: Optional[str] = None  # CandidateChunk â†’ Candidateë¡œ ë³€ê²½
) -> List[Evidence]:
    """ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ë°°ì¹˜ ë‚´ ê° í›„ë³´ì— ëŒ€í•œ Evidenceë¥¼ ì§ì ‘ ìƒì„±í•œë‹¤."""
    try:
        llm = get_llm(llm_config)
        structured_llm = llm.with_structured_output(BatchEvidenceLLMResult)
        
        # ref ë§¤í•‘ (Candidate ê°ì²´ìš©)
        ref_to_id = {f"ref:{idx}": f"candidate_{idx}" for idx, candidate in enumerate(batch)}
        id_to_ref = {v: k for k, v in ref_to_id.items()}

        batch_messages = get_batch_prompt_for_candidates(batch, query, revised_query, id_to_ref)
        system_text = await get_system_prompt()

        messages = [
            SystemMessage(content=system_text),
            batch_messages,
        ]

        # LLM ì…ë ¥ ë¡œê·¸ (ì´ë¯¸ì§€ ë°ì´í„° ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥)
        logger.info(f"[LLM Input] batch={batch_id}, candidates={len(batch)}, query={query}")
        if isinstance(batch_messages.content, list):
            text_parts = [p.get("text", "") for p in batch_messages.content if p.get("type") == "text"]
            image_count = sum(1 for p in batch_messages.content if p.get("type") == "image_url")
            logger.info(f"[LLM Input] batch={batch_id}, text={''.join(text_parts)}, images={image_count}")
        else:
            logger.info(f"[LLM Input] batch={batch_id}, messages={batch_messages.content}")

        # LLM í˜¸ì¶œ
        result: BatchEvidenceLLMResult = cast(BatchEvidenceLLMResult, await structured_llm.ainvoke(messages))
        
        # LLM ì¶œë ¥ ë¡œê·¸
        logger.info(f"[LLM Output] batch={batch_id}, evidences_count={len(result.candidate_evidences)}")
        for idx, ev in enumerate(result.candidate_evidences):
            logger.info(f"[LLM Output] batch={batch_id}, idx={idx}, candidate_id={ev.candidate_id}, relevance={ev.relevance_score}, evidence={ev.evidence}")
        
        # Evidence ê°ì²´ ìƒì„± (relevance threshold ë¯¸ë§Œì€ í•„í„°ë§)
        evidences = []
        RELEVANCE_THRESHOLD = 0.3  # ìµœì†Œ relevance score
        
        for evidence_item in result.candidate_evidences:  # ì˜¬ë°”ë¥¸ í•„ë“œëª… ì‚¬ìš©
            # relevance_scoreê°€ threshold ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
            if evidence_item.relevance_score < RELEVANCE_THRESHOLD:
                logger.info(f"[Evidence Filtered] batch={batch_id}, candidate_id={evidence_item.candidate_id}, relevance={evidence_item.relevance_score} < {RELEVANCE_THRESHOLD}, skipping")
                continue
            
            # ref_idë¥¼ ì‹¤ì œ candidate ì •ë³´ë¡œ ë§¤í•‘
            candidate_idx = int(evidence_item.candidate_id.split(":")[1])
            candidate = batch[candidate_idx]
            logger.debug("candidate", candidate)
            candidate_result = getattr(candidate, "result", None)
            # source ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì‚¬ìš©ì í‘œì‹œìš©)
            source_str = "Unknown"
            if candidate.source:
                logger.debug(f"[Evidence ID Extraction] candidate_idx={candidate_idx}, source={candidate.source}")
                source_parts = []
                for src in candidate.source:
                    if isinstance(src, dict):
                        # dictì—ì„œ ì˜ë¯¸ìˆëŠ” ì •ë³´ ì¶”ì¶œ (ì‚¬ìš©ì í‘œì‹œìš©)
                        if 'document_name' in src:
                            source_parts.append(src['document_name'])
                        elif 'file_name' in src:
                            source_parts.append(src['file_name'])
                        elif 'title' in src:
                            source_parts.append(src['title'])
                        else:
                            # ID ì •ë³´ëŠ” ì‚¬ìš©ì í‘œì‹œìš© sourceì—ì„œ ì œì™¸
                            continue
                    else:
                        source_parts.append(str(src))
                source_str = ", ".join(source_parts) if source_parts else "Unknown"
            
            # candidate.source ì „ì²´ë¥¼ source_idë¡œ ì‚¬ìš© (ë“œë¡­ë‹¤ìš´ìš©)
            source_id_list = candidate.source if candidate.source else []

            evidence = Evidence(
                source=source_str,  # ë¬¸ìì—´ë¡œ ë³€í™˜ëœ ì†ŒìŠ¤
                content=evidence_item.evidence,  # ì˜¬ë°”ë¥¸ í•„ë“œëª… ì‚¬ìš©
                relevance_score=evidence_item.relevance_score,
                toc_title=_extract_toc_title(candidate.metadata or {}, candidate_result=candidate_result),
                toc_summary=getattr(candidate, "metadata", {}).get("toc_summary")
                if isinstance(getattr(candidate, "metadata", {}), dict)
                else None,
                source_id=source_id_list,  # candidate.source ì „ì²´ ì‚¬ìš©
                evidence_type="rag",
                metadata={
                    "original_result": candidate.result,
                    "original_source": candidate.source,  # ì›ë³¸ ì†ŒìŠ¤ ì •ë³´ ë³´ì¡´
                    "ref_id": evidence_item.candidate_id,
                    "batch_id": batch_id
                }
            )
            logger.info(f"[Evidence Created] batch={batch_id}, candidate_idx={candidate_idx}, source_ids_count={len(source_id_list)}, relevance={evidence_item.relevance_score}")
            evidences.append(evidence)
        
        return evidences
        
    except Exception as e:
        logger.error(f"ë°°ì¹˜ {batch_id} Evidence ìƒì„± ì‹¤íŒ¨: {e}")
        return []


async def gather_direct_evidences(
    batches: List[List[CandidateChunk]],
    user_query: str,
    callback: Optional[Callable] = None,
) -> List[Evidence]:
    """
    ëª¨ë“  ë°°ì¹˜ì—ì„œ ì§ì ‘ Evidenceë¥¼ ìˆ˜ì§‘ (ìŠ¤íŠ¸ë¦¬ë°).
    """

    # ì‘ì—… ìƒì„± ë° ë§¤í•‘
    created_tasks: List[asyncio.Task] = []
    for i, batch in enumerate(batches):
        t = asyncio.create_task(generate_evidences_for_batch(batch, f"batch_{i+1}", user_query))
        created_tasks.append(t)

    evidences: List[Evidence] = []
    total_batches = len(batches)
    success = 0

    # ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
    for fut in asyncio.as_completed(created_tasks):
        try:
            result = await fut
            items = cast(List[Evidence], result)
            evidences.extend(items)
            success += 1
            await send_progress(
                callback,
                "RAG Candidate Analyzer",
                f"Evidences {success}/{total_batches} generated",
                int(20 + (success / total_batches) * 70),
            )
        except Exception as err:
            logger.error(f"[EVID] generation failed: {err}", exc_info=True)

    return evidences


async def gather_direct_evidences_for_candidates(
    batches: List[List[Candidate]],
    user_query: str,
    revised_query: Optional[str] = None,
    callback: Optional[Callable] = None,
) -> List[Evidence]:
    """
    ëª¨ë“  Candidate ë°°ì¹˜ì—ì„œ ì§ì ‘ Evidenceë¥¼ ìˆ˜ì§‘ (ìŠ¤íŠ¸ë¦¬ë°).
    """

    # ì‘ì—… ìƒì„± ë° ë§¤í•‘
    created_tasks: List[asyncio.Task] = []
    for i, batch in enumerate(batches):
        t = asyncio.create_task(generate_evidences_for_candidate_batch(batch, f"batch_{i+1}", user_query, revised_query))
        created_tasks.append(t)

    evidences: List[Evidence] = []
    total_batches = len(batches)
    success = 0

    # ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
    for fut in asyncio.as_completed(created_tasks):
        try:
            result = await fut
            items = cast(List[Evidence], result)
            evidences.extend(items)
            success += 1
            await send_progress(
                callback,
                "RAG Candidate Analyzer",
                f"Evidences {success}/{total_batches} generated",
                int(20 + (success / total_batches) * 70),
            )
        except Exception as err:
            logger.error(f"[EVID] generation failed: {err}", exc_info=True)

    return evidences


async def rag_analyzer_node(
    state: GeneralAnswerState, config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """RAG ê²€ìƒ‰ í›„ë³´ë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê³  ì •ë³´ ì í•©ì„±ì„ í‰ê°€í•˜ëŠ” ë…¸ë“œ (Candidate ì§ì ‘ ì²˜ë¦¬)"""
    
    log_section(logger, "RAG CANDIDATE ANALYZER (ASYNC)")
    configurable = config.get("configurable", {}) if config else {}
    callback = configurable.get("progress_callback")

    # ì´ˆê¸° ì§„í–‰ ìƒí™© ë©”ì‹œì§€
    await send_progress(
        callback,
        "RAG Candidate Analyzer",
        "Starting analysis of RAG retrieved candidates...",
        0,
    )

    try:
        # ì…ë ¥ ë°ì´í„° ê²€ì¦ (ì´ì œ List[Candidate] ë°˜í™˜)
        instruction, user_query, revised_query, candidates = validate_input_data(state)

        if not candidates:
            await send_progress(
                callback,
                "RAG Candidate Analyzer",
                "No candidates available for analysis.",
                100,
            )
            return create_no_candidates_response(state)

        # 1ë‹¨ê³„: í›„ë³´ë“¤ì„ ë°°ì¹˜ë¡œ ê·¸ë£¹í•‘ (Candidate ê°ì²´ìš©)
        batches = group_candidates_into_batches(candidates, max_batch_size=3)
        
        await send_progress(
            callback,
            "RAG Candidate Analyzer",
            f"Grouped {len(candidates)} candidates into {len(batches)} batches.",
            20,
        )

        # 2ë‹¨ê³„: ë°°ì¹˜ë³„ë¡œ ì§ì ‘ Evidence ìƒì„± (Candidateìš© ìŠ¤íŠ¸ë¦¬ë°)
        evidences = await gather_direct_evidences_for_candidates(batches, user_query, revised_query, callback)

        # 3ë‹¨ê³„: ìƒì„±ëœ Evidenceë¡œ ê°„ë‹¨ ë¶„ì„ ì‚°ì¶œ
        analysis_result = synthesize_analysis_from_evidences(
            evidences, candidates
        )

        await send_progress(callback, "RAG Candidate Analyzer", "Finished analysis of RAG retrieved candidates.", 100)
        
        # ê¸°ë³¸ ì‘ë‹µ ìƒì„±
        response = create_success_response(
            state, evidences, analysis_result, user_query, candidates, batches
        )
        
        # 4ë‹¨ê³„: Evidenceê°€ ìƒì„±ë˜ì—ˆìœ¼ë©´ ìë™ìœ¼ë¡œ data_generator ì‹¤í–‰
        if evidences:
            logger.info("ğŸ”„ RAG Analyzer: Evidence ìƒì„± ì™„ë£Œ, data_generator ìë™ ì‹¤í–‰ ì‹œì‘")
            try:
                # data_generator_nodeë¥¼ ì„í¬íŠ¸í•˜ê³  ì‹¤í–‰
                from rag.nodes.data_generator.generate_data import data_generator_node
                
                # í˜„ì¬ stateì— responseë¥¼ ë³‘í•©í•˜ì—¬ ìƒˆë¡œìš´ state ìƒì„±
                updated_state = GeneralAnswerState(**{**state.__dict__, **response})
                
                # data_generator ì‹¤í–‰
                data_gen_result = await data_generator_node(updated_state, config)
                
                # data_generator ê²°ê³¼ë¥¼ responseì— ë³‘í•©
                if data_gen_result and isinstance(data_gen_result, dict):
                    logger.info(f"ğŸ”„ RAG Analyzer: data_generator ì‹¤í–‰ ì™„ë£Œ, ê²°ê³¼ ë³‘í•©")
                    response.update(data_gen_result)
                else:
                    logger.warning("ğŸ”„ RAG Analyzer: data_generatorê°€ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•¨")
                    
            except Exception as data_gen_error:
                logger.error(f"ğŸ”„ RAG Analyzer: data_generator ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {data_gen_error}", exc_info=True)
                # data_generator ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
        else:
            logger.info("ğŸ”„ RAG Analyzer: Evidenceê°€ ì—†ì–´ data_generator ìŠ¤í‚µ")
        
        return response

    except Exception as e:
        await send_progress(callback, "RAG Candidate Analyzer", "Finished analysis of RAG retrieved candidates.", 100)
        logger.error(f"Error in RAG candidate analysis: {e}", exc_info=True)
        return create_error_response(state, e)
